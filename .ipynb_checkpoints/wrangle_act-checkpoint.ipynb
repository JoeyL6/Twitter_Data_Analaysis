{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### programmatically downloaded using the Requests library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime as dt\n",
    "import matplotlib as mp\n",
    "import seaborn as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store file to file handler\n",
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "code = r.status_code\n",
    "print(code)\n",
    "#save downloaded file to local folder\n",
    "open('image-predictions.tsv', 'wb').write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tweet ID, retweet count, and favorite count using Tweepy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read twitte IDs\n",
    "\n",
    "#read the twitter-archive-enhanced.csv file in to dataframe\n",
    "df_1 = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_1\n",
    "#convert the first column of the datafram(tweet id) to a list\n",
    "IDlist = df_1['tweet_id'].tolist()\n",
    "IDlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pull twitter status json from twitter API and store them into a list\n",
    "import tweepy\n",
    "\n",
    "# key and token omitted for privacy\n",
    "consumer_key = '*'\n",
    "consumer_secret = '*'\n",
    "access_token = '*'\n",
    "access_secret = '*'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit  = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "tweet_list = []\n",
    "\n",
    "for tid in IDlist:\n",
    "    try:\n",
    "        tweet = api.get_status(tid, tweet_mode='extended')\n",
    "        tweet_list.append(tweet._json)\n",
    "    except:\n",
    "        print('tweet ' + str(tid) + \"doesn't\" exist')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if all tweet status has been downloaded\n",
    "len(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json to txt file\n",
    "\n",
    "# type(tweet_json)\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    for tweet_json in tweet_list:\n",
    "        json.dump(tweet_json, outfile)\n",
    "        outfile.write('\\n') #add a newline character at the end of each json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json from text\n",
    "\n",
    "tweet_df_raw = pd.read_json('tweet_json.txt', lines = 'True')\n",
    "tweet_df = tweet_df_raw[['id', 'retweet_count', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 3 dataframes from different sources\n",
    "archive_df = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "image_df = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "status_df = tweet_df.copy()\n",
    "status_df.rename(columns = {\"id\": \"tweet_id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.info()\n",
    "archive_df.sample()\n",
    "type(archive_df.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issues in archive dataframe\n",
    "1. Quality issues:\n",
    "    - Retweets: some of the tweets in this dataframe are retweet, as mentioned in the project detail. These retweet are not supposed to be included in the analysis\n",
    "    - Unnecessary information: text, sources are not needed for analysis. Retweeted_status_id and retweeted_status_user_id, and retweetd_status_timestamp are not needed after data cleaning procedure. \n",
    "    - The rating_numerator and rating_denominator can be combined into one column in decimal form.\n",
    "    - Wrong data type for tweet id. Since no calculations will be applied on tweet ID, the tweet ID needs to be str instead of int64.\n",
    "    - The timestamp column has wrong data type. \n",
    "2. Tidiess issues\n",
    "    - Dog stages are not in one column, instead, they are divided into 4.\n",
    "    - Date and time should be two variables for the purpose of analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.info()\n",
    "image_df.p1.value_counts()\n",
    "#image_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issues in image dataframe\n",
    "1. Quality issues:\n",
    "    - Non-descriptive column headers: p1, p1_conf, p1_dog, p2, p2_dog, p3, p3_conf, p3_dog etc. \n",
    "    - Some of the dog breeds has first letter capitalized and some are not. \n",
    "    - Some of the dog breeds are misspelled (ie. 19 of the breeds is website) or intended misspelled (ie. cheeseburger) \n",
    "    \n",
    "2. Tidiess issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issues in status dataframe\n",
    "1. Quality issues:\n",
    "    - wrong data type for tweet ID\n",
    "2. Tidiess issues\n",
    "\n",
    "### Summary\n",
    "Quality issues:\n",
    "    1. Retweets: some of the tweets in this dataframe are retweet. as mentioned in the project detail, These retweets are not supposed to be included in the analysis.\n",
    "    2. Unnecessary information: text, sources are not needed for analysis. Retweeted_status_id and retweeted_status_user_id, and retweetd_status_timestamp are not needed after data cleaning procedure. \n",
    "    3. Wrong data type for tweet id. Since no calculations will be applied on tweet ID, the tweet ID needs to be str instead of int64.\n",
    "    4. The timestamp column has wrong data type. \n",
    "    5. Non-descriptive column headers: p1, p1_conf, p1_dog, p2, p2_dog, p3, p3_conf, p3_dog etc. \n",
    "    6. Some of the dog breeds has first letter capitalized and some are not. \n",
    "    7. Many ratings' denominator are not 10, even the numerator which greater than 10 is the feature of this twitter account, keep the denominator same is vital to later analysis. \n",
    "    8. Date and time are in the same column, this is not necessarily a tidyness issue, because its nothing wrong with putting this two in same column. It still need tobe parsed because we will perfome analysis around date and time later. \n",
    "\n",
    "Tidyness issues:\n",
    "    1. One observation unit does not form a table. At least, retweet_count and favorite_count needs to be part of the archive dataframe to form a complete observation unit. \n",
    "    2. Dog stages are not in one column, instead, they are divided into 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #1 : retweets\n",
    "\n",
    "#### Define:\n",
    "Remove all tweet rows that has nonnull value in retweeted_status_id column in archive dataframe.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy\n",
    "archive_df_clean = archive_df.copy()\n",
    "\n",
    "# only keep tweet whose retweeted_status_id is NAn\n",
    "archive_df_clean = archive_df_clean[archive_df_clean['retweeted_status_id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #2: Unnecessary information\n",
    "#### Define:\n",
    "Remove columns: expanded_urls, in_reply_to_status_id, in_reply_to_user_id, text, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, source. \n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "archive_df_clean = archive_df_clean.drop(columns=['expanded_urls', 'in_reply_to_status_id', 'in_reply_to_user_id', 'text', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp', 'source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(archive_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #3: Wrong datatype for tweet ID\n",
    "#### Define:\n",
    "Change data type of Tweet ID to string\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the datatype of tweet_id\n",
    "archive_df_clean['tweet_id'] = archive_df_clean['tweet_id'].astype(str)\n",
    "# change the datatype of tweet_id column in status_df as well\n",
    "status_df['tweet_id'] = status_df['tweet_id'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #4: Wrong datatype for time stamp column\n",
    "#### Define:\n",
    "Remove columns: change the timestamp column to \n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis the timestamp column\n",
    "type(archive_df_clean['timestamp'])\n",
    "\n",
    "archive_df_clean.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single out first 19 digits of the timestamp\n",
    "archive_df_clean['timestamp'] = archive_df_clean.timestamp.str[:19]\n",
    "\n",
    "archive_df_clean['timestamp'] = pd.to_datetime(archive_df_clean['timestamp'], format = \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #5: Non-Descriptive column header in image dataframe\n",
    "#### Define:\n",
    "change following column headers:\n",
    "\n",
    "- p1 -> prediction_1\n",
    "- p1_conf -> prediction_1_confidence\n",
    "- p1_dog -> prediction_1_result\n",
    "- p2 -> prediction_2\n",
    "- p2_conf -> prediction_2_confidence\n",
    "- p2_dog -> prediction_2_result\n",
    "- p3 -> prediction_3\n",
    "- p3_conf -> prediction_3_confidence\n",
    "- p3_dog -> prediction_3_result\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_clean = image_df.copy()\n",
    "image_df_clean.rename(columns={'p1': 'prediction_1', 'p1_conf': 'prediction_1_confidence', 'p1_dog': 'prediction_1_result'}, inplace=True)\n",
    "image_df_clean.rename(columns={'p2': 'prediction_2', 'p2_conf': 'prediction_2_confidence', 'p2_dog': 'prediction_2_result'}, inplace=True)\n",
    "image_df_clean.rename(columns={'p3': 'prediction_3', 'p3_conf': 'prediction_3_confidence', 'p3_dog': 'prediction_3_result'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_clean.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #6: the first letter of all dog names are not all capitalized.\n",
    "#### Define:\n",
    "capitalize the first letter of all dog breeds\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_clean.prediction_1 = image_df_clean.prediction_1.str.title()\n",
    "image_df_clean.prediction_2 = image_df_clean.prediction_2.str.title()\n",
    "image_df_clean.prediction_3 = image_df_clean.prediction_3.str.title()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_clean.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #7: Many ratings' denominator are not 10\n",
    "#### Define:\n",
    "Scale tweets who's denominators more than 10 or less than 10 to 10\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.info()\n",
    "archive_df_clean.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in archive_df_clean.iterrows():\n",
    "    if row['rating_denominator'] == 0:\n",
    "        new_denominator = 10\n",
    "        archive_df_clean.set_value(index, 'rating_denominator', new_denominator)\n",
    "    elif row['rating_denominator'] != 10:\n",
    "        print(row['tweet_id'])\n",
    "        new_denominator = 10\n",
    "        new_numerator = round((row['rating_numerator']/row['rating_denominator'])*10, 1)\n",
    "        print(row['rating_denominator'])\n",
    "        print(new_denominator)\n",
    "        print(row['rating_numerator'])\n",
    "        print(new_numerator)\n",
    "        archive_df_clean.set_value(index, 'rating_denominator', new_denominator)\n",
    "        archive_df_clean.set_value(index, 'rating_numerator', new_numerator)\n",
    "#     else:\n",
    "#         new_denominator = rating_denominator\n",
    "#         new_numerator = rating_numerator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue #8: date and time are in one column\n",
    "#### Define:\n",
    "seperate date and time into two columns for easier visualization regards the time in a day.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean['date'] = archive_df_clean['timestamp'].apply(lambda time: time.strftime('%m-%d-%Y'))\n",
    "archive_df_clean['time'] = archive_df_clean['timestamp'].apply(lambda time: time.strftime('%H:%M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tidyness issue #1: dog stages not in one column\n",
    "#### Define\n",
    "combine doggo, floofer, pupper and puppo columns into stage column\n",
    "\n",
    "#### Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean_stage = archive_df_clean.copy()\n",
    "\n",
    "archive_df_clean_stage[\"stage\"] = \"\"\n",
    "\n",
    "for index, row in archive_df_clean_stage.iterrows():\n",
    "    if row[\"doggo\"]  == \"doggo\":\n",
    "        #print(row[\"doggo\"])\n",
    "        archive_df_clean_stage.loc[index, \"stage\"] = \"doggo\"\n",
    "        \n",
    "    elif row[\"floofer\"] == \"floofer\":\n",
    "        #print(row[\"floofer\"])\n",
    "        archive_df_clean_stage.loc[index, \"stage\"] = \"floofer\"\n",
    "        \n",
    "    elif row[\"pupper\"] == \"pupper\":\n",
    "        archive_df_clean_stage.loc[index, \"stage\"] = \"pupper\"\n",
    "        \n",
    "    elif row[\"puppo\"] == \"puppo\":\n",
    "        archive_df_clean_stage.loc[index, \"stage\"] = \"puppo\"\n",
    "        \n",
    "    else:\n",
    "        archive_df_clean_stage.loc[index, \"stage\"] = \"N/A\"\n",
    "\n",
    "#drop 4 original columns which contains the stage of dogs\n",
    "#archive_df_clean_stage.drop([\"doggo\", \"floofer\", \"pupper\", \"puppo\"], axis = 1)        \n",
    "archive_df_clean = archive_df_clean_stage.copy()\n",
    "archive_df_clean = archive_df_clean.drop([\"doggo\", \"floofer\", \"pupper\", \"puppo\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean[\"stage\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tidyness issue #2: observation unit are not in same column\n",
    "#### Define\n",
    "inner join three dataframe by twitter ID to forme the observation unit.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#twitter_df_final = pd.concat([archive_df_clean, status_df, image_df_clean], axis=1, join='inner')\n",
    "#create a copy of image_df which has only tweet_id and related data on prediction 1.\n",
    "image_df_tomerge = image_df_clean.loc[:, ['tweet_id', 'prediction_1', 'prediction_1_confidence','prediction_1_result']]\n",
    "image_df_tomerge['tweet_id'] = image_df_tomerge['tweet_id'].astype(str)\n",
    "twitter_df_merged = pd.merge(pd.merge(archive_df_clean, status_df, on='tweet_id'), image_df_tomerge, on='tweet_id')#pd.merge(status_df, image_df_clean, on = 'tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_merged.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights #1\n",
    "\n",
    "### Breeds: Most Popular vs Most loved\n",
    "\n",
    "Assume the neural network predicted breeds right, which dog breeds get rated most? which dog breeds gets most favorite? Are they the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only predictions where the result is a breed of dogs\n",
    "prediction_true = twitter_df_merged[twitter_df_merged['prediction_1_result'] == True]\n",
    "\n",
    "#find the top20 most popular breeds and return its associated data\n",
    "top20 = prediction_true['prediction_1'].value_counts().head(20).index\n",
    "top20_df = twitter_df_merged.loc[twitter_df_merged.prediction_1.isin(top20)]\n",
    "\n",
    "#find the mean favorites for this top 20 most tweeted dog breeds\n",
    "fav_summary = top20_df.groupby('prediction_1', as_index=False).mean().sort_values('favorite_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_mostfav = fav_summary[['prediction_1', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top20_mosttweeted = top20_df['prediction_1'].value_counts()\n",
    "top20_mosttweeted = pd.DataFrame(top20_mosttweeted).reset_index()\n",
    "top20_mosttweeted.columns = ['Breeds', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort two dataframes\n",
    "top20_mostfav = top20_mostfav.sort_values(by='favorite_count', ascending=False)\n",
    "top20_mosttweeted = top20_mosttweeted.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>French_Bulldog</td>\n",
       "      <td>17751.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Samoyed</td>\n",
       "      <td>13449.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Golden_Retriever</td>\n",
       "      <td>12222.848921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eskimo_Dog</td>\n",
       "      <td>11875.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Labrador_Retriever</td>\n",
       "      <td>11714.042105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cocker_Spaniel</td>\n",
       "      <td>11584.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pembroke</td>\n",
       "      <td>11316.784091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chesapeake_Bay_Retriever</td>\n",
       "      <td>10489.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>German_Shepherd</td>\n",
       "      <td>10054.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chow</td>\n",
       "      <td>10044.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Staffordshire_Bullterrier</td>\n",
       "      <td>9748.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Malamute</td>\n",
       "      <td>8725.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>8711.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Miniature_Pinscher</td>\n",
       "      <td>8644.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shetland_Sheepdog</td>\n",
       "      <td>8497.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>8051.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Siberian_Husky</td>\n",
       "      <td>6943.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toy_Poodle</td>\n",
       "      <td>6574.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pug</td>\n",
       "      <td>5871.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Maltese_Dog</td>\n",
       "      <td>2950.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 prediction_1  favorite_count\n",
       "5              French_Bulldog    17751.769231\n",
       "15                    Samoyed    13449.725000\n",
       "7            Golden_Retriever    12222.848921\n",
       "4                  Eskimo_Dog    11875.555556\n",
       "8          Labrador_Retriever    11714.042105\n",
       "3              Cocker_Spaniel    11584.185185\n",
       "12                   Pembroke    11316.784091\n",
       "0    Chesapeake_Bay_Retriever    10489.826087\n",
       "6             German_Shepherd    10054.500000\n",
       "2                        Chow    10044.024390\n",
       "18  Staffordshire_Bullterrier     9748.315789\n",
       "9                    Malamute     8725.310345\n",
       "1                   Chihuahua     8711.734177\n",
       "11         Miniature_Pinscher     8644.590909\n",
       "16          Shetland_Sheepdog     8497.166667\n",
       "13                 Pomeranian     8051.447368\n",
       "17             Siberian_Husky     6943.050000\n",
       "19                 Toy_Poodle     6574.973684\n",
       "14                        Pug     5871.851852\n",
       "10                Maltese_Dog     2950.611111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breeds</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Golden_Retriever</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labrador_Retriever</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pembroke</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pug</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chow</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samoyed</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toy_Poodle</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Malamute</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cocker_Spaniel</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>French_Bulldog</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chesapeake_Bay_Retriever</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miniature_Pinscher</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Siberian_Husky</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>German_Shepherd</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Staffordshire_Bullterrier</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shetland_Sheepdog</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maltese_Dog</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eskimo_Dog</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Breeds  count\n",
       "0            Golden_Retriever    139\n",
       "1          Labrador_Retriever     95\n",
       "2                    Pembroke     88\n",
       "3                   Chihuahua     79\n",
       "4                         Pug     54\n",
       "5                        Chow     41\n",
       "6                     Samoyed     40\n",
       "7                  Pomeranian     38\n",
       "8                  Toy_Poodle     38\n",
       "9                    Malamute     29\n",
       "10             Cocker_Spaniel     27\n",
       "11             French_Bulldog     26\n",
       "12   Chesapeake_Bay_Retriever     23\n",
       "13         Miniature_Pinscher     22\n",
       "14             Siberian_Husky     20\n",
       "15            German_Shepherd     20\n",
       "16  Staffordshire_Bullterrier     19\n",
       "17          Shetland_Sheepdog     18\n",
       "18                Maltese_Dog     18\n",
       "19                 Eskimo_Dog     18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display two table\n",
    "display(top20_mostfav)\n",
    "display(top20_mosttweeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. multiple json in txt line by line: https://stackoverflow.com/questions/17055117/python-json-dump-append-to-txt-with-each-variable-on-new-line\n",
    "2. load json from txt line by line: https://stackoverflow.com/questions/21533894/how-to-read-line-delimited-json-from-large-file-line-by-line\n",
    "3. create dataframe from json file: https://stackoverflow.com/questions/47925828/how-to-create-a-pandas-dataframe-using-tweepy\n",
    "4. keep only rows who has NaN in a certain column: https://stackoverflow.com/questions/25430995/keeping-nan-values-and-dropping-nonmissing-values\n",
    "5. str to datetime: https://stackoverflow.com/questions/17134716/convert-dataframe-column-type-from-string-to-datetime\n",
    "6. iterate rows to change value https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "7. use isin\n",
    "8. combine to different columns into 1: \n",
    "9. merge 3 dataframes\n",
    "https://stackoverflow.com/questions/23668427/pandas-joining-multiple-dataframes-on-columns\n",
    "10. create empty column(s)\n",
    "https://stackoverflow.com/questions/16327055/how-to-add-an-empty-column-to-a-dataframe\n",
    "11. conditional mean\n",
    "https://stackoverflow.com/questions/44787916/conditional-mean-over-a-pandas-dataframe\n",
    "12. assign column name to series\n",
    "https://stackoverflow.com/questions/28503445/assigning-column-names-to-a-pandas-series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
